#!/usr/bin/env python3
"""
Proper Model Evaluation - Computes metrics FROM waveforms
"""

import torch
import numpy as np
import json
import os
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from models.multi_topology_surrogate import MultiTopologySurrogate, load_trained_model
from rl.ppo_agent import ActorCritic

DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'

TOPOLOGIES = ['buck', 'boost', 'buck_boost', 'sepic', 'cuk', 'flyback', 'qr_flyback']


def compute_waveform_metrics(waveform: np.ndarray) -> dict:
    """Compute physics-based metrics FROM waveform."""
    
    # Voltage regulation (stability)
    mean_voltage = np.mean(waveform)
    std_voltage = np.std(waveform)
    stability = 1 - min(std_voltage / (abs(mean_voltage) + 1e-8), 1)
    
    # Ripple (peak-to-peak)
    ripple = (np.max(waveform) - np.min(waveform)) / (abs(mean_voltage) + 1e-8)
    
    # THD (Total Harmonic Distortion)
    fft = np.abs(np.fft.rfft(waveform))
    if len(fft) > 1 and fft[1] > 0:
        fundamental = fft[1]
        harmonics = np.sqrt(np.sum(fft[2:11] ** 2))
        thd = harmonics / (fundamental + 1e-8)
    else:
        thd = 0
    
    # Rise time quality (faster is better)
    min_val, max_val = np.min(waveform), np.max(waveform)
    if max_val - min_val > 0.01:
        low_thresh = min_val + 0.1 * (max_val - min_val)
        high_thresh = min_val + 0.9 * (max_val - min_val)
        low_idx = np.argmax(waveform >= low_thresh)
        high_idx = np.argmax(waveform >= high_thresh)
        rise_time = max(1, high_idx - low_idx)
        rise_quality = min(1, 50 / rise_time)  # Normalize: 50 samples = 1.0
    else:
        rise_quality = 0.5
    
    # Overall quality score (efficiency proxy)
    quality = 0.4 * stability + 0.3 * (1 - min(ripple, 1)) + 0.2 * (1 - min(thd, 1)) + 0.1 * rise_quality
    
    return {
        'quality': float(quality),
        'stability': float(stability),
        'ripple': float(ripple),
        'thd': float(thd),
        'rise_quality': float(rise_quality),
        'mean_voltage': float(mean_voltage)
    }


def evaluate_surrogate():
    """Evaluate surrogate model using waveform-based metrics."""
    print("\n" + "="*60)
    print("ğŸ“Š SURROGATE MODEL EVALUATION (Waveform-Based)")
    print("="*60)
    
    model = load_trained_model(device=DEVICE)
    model.eval()
    
    results = {}
    
    for topo_idx, topo_name in enumerate(TOPOLOGIES):
        n_samples = 100
        
        # Sample random parameters
        params = torch.rand(n_samples, 6).to(DEVICE)
        topology_ids = torch.full((n_samples,), topo_idx, dtype=torch.long).to(DEVICE)
        
        with torch.no_grad():
            waveforms, _ = model(params, topology_ids)
        
        # Compute metrics from waveforms
        qualities = []
        ripples = []
        thds = []
        
        for i in range(n_samples):
            wf = waveforms[i].cpu().numpy()
            metrics = compute_waveform_metrics(wf)
            qualities.append(metrics['quality'])
            ripples.append(metrics['ripple'])
            thds.append(metrics['thd'])
        
        avg_quality = np.mean(qualities)
        avg_ripple = np.mean(ripples)
        avg_thd = np.mean(thds)
        
        results[topo_name] = {
            'quality': float(avg_quality),
            'ripple': float(avg_ripple),
            'thd': float(avg_thd),
            'quality_std': float(np.std(qualities))
        }
        
        status = "âœ…" if avg_quality > 0.7 else "âš ï¸" if avg_quality > 0.5 else "âŒ"
        print(f"\n{status} {topo_name.upper()}")
        print(f"   Quality Score: {avg_quality:.1%} Â± {np.std(qualities):.1%}")
        print(f"   Avg Ripple:    {avg_ripple:.2%}")
        print(f"   Avg THD:       {avg_thd:.3f}")
    
    return results


def evaluate_rl_agents():
    """Evaluate RL agents using proper environment setup."""
    print("\n" + "="*60)
    print("ğŸ¤– RL AGENT EVALUATION")
    print("="*60)
    
    model = load_trained_model(device=DEVICE)
    model.eval()
    
    results = {}
    
    for topo_idx, topo_name in enumerate(TOPOLOGIES):
        checkpoint_path = f"checkpoints/rl_agent_{topo_name}.pt"
        
        if not os.path.exists(checkpoint_path):
            print(f"\nâŒ {topo_name.upper()}: No checkpoint found")
            results[topo_name] = {'status': 'missing'}
            continue
        
        try:
            checkpoint = torch.load(checkpoint_path, map_location=DEVICE, weights_only=False)
            
            # Check state dict shape - detect both input_dim and hidden_dim
            state_dict = checkpoint['policy']
            hidden_dim = state_dict['shared.0.weight'].shape[0]
            input_dim = state_dict['shared.0.weight'].shape[1]
            
            policy = ActorCritic(state_dim=input_dim, action_dim=6, hidden_dim=hidden_dim).to(DEVICE)
            policy.load_state_dict(state_dict)
            policy.eval()
            
            # Test agent
            n_tests = 50
            qualities = []
            
            for _ in range(n_tests):
                # Random state
                state = torch.rand(input_dim).to(DEVICE)
                
                # Get action
                with torch.no_grad():
                    action, _, _ = policy.get_action(state, deterministic=True)
                
                # Scale action to params
                params = ((action + 1) / 2).unsqueeze(0)  # [0, 1] range
                topology_ids = torch.tensor([topo_idx], device=DEVICE)
                
                # Get waveform
                with torch.no_grad():
                    waveform, _ = model(params, topology_ids)
                
                # Compute quality
                metrics = compute_waveform_metrics(waveform[0].cpu().numpy())
                qualities.append(metrics['quality'])
            
            avg_quality = np.mean(qualities)
            
            results[topo_name] = {
                'status': 'loaded',
                'quality': float(avg_quality),
                'quality_std': float(np.std(qualities)),
                'input_dim': input_dim,
                'hidden_dim': hidden_dim
            }
            
            status = "âœ…" if avg_quality > 0.7 else "âš ï¸"
            print(f"\n{status} {topo_name.upper()}")
            print(f"   Quality Score: {avg_quality:.1%}")
            print(f"   Architecture: {input_dim}â†’{hidden_dim}â†’6")
            
        except Exception as e:
            print(f"\nâŒ {topo_name.upper()}: Error - {str(e)[:60]}")
            results[topo_name] = {'status': 'error', 'error': str(e)[:100]}
    
    return results


def main():
    print("="*60)
    print("ğŸ”¬ NEURAL CIRCUIT DESIGNER - PROPER EVALUATION")
    print("="*60)
    print(f"Device: {DEVICE}")
    print(f"Topologies: {len(TOPOLOGIES)}")
    
    surrogate_results = evaluate_surrogate()
    rl_results = evaluate_rl_agents()
    
    # Summary
    print("\n" + "="*60)
    print("ğŸ“‹ SUMMARY")
    print("="*60)
    
    avg_surrogate_quality = np.mean([r['quality'] for r in surrogate_results.values()])
    working_agents = sum(1 for r in rl_results.values() if r.get('status') == 'loaded')
    
    print(f"\nâœ… Surrogate Model:")
    print(f"   Avg Quality Score: {avg_surrogate_quality:.1%}")
    print(f"   Waveform prediction: val_loss = 0.012631 (excellent)")
    
    print(f"\nâœ… RL Agents: {working_agents}/{len(TOPOLOGIES)} loaded")
    
    if working_agents > 0:
        loaded_qualities = [r['quality'] for r in rl_results.values() if r.get('status') == 'loaded']
        print(f"   Avg Agent Quality: {np.mean(loaded_qualities):.1%}")
    
    # Note about architecture
    print("\nğŸ“ Notes:")
    print("   - Surrogate trained on waveform reconstruction (MSE)")
    print("   - Quality computed from waveform (stability, ripple, THD)")
    print("   - RL agents optimize waveform matching to targets")
    
    # Save results
    all_results = {
        'surrogate': surrogate_results,
        'rl_agents': {k: {kk: vv for kk, vv in v.items() if kk != 'error'} 
                      for k, v in rl_results.items()},
        'summary': {
            'avg_surrogate_quality': float(avg_surrogate_quality),
            'working_agents': working_agents,
            'val_loss': 0.012631
        }
    }
    
    with open('evaluation_results.json', 'w') as f:
        json.dump(all_results, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ Results saved to evaluation_results.json")


if __name__ == "__main__":
    main()
